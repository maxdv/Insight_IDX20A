{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install q keras==2.3.1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  *\n",
    "from keras.optimizers import *\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:00<00:00, 391.26it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 410.79it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier_directory = os.getcwd()\n",
    "pathway_to_clips = classifier_directory + '/movie_clips'\n",
    "pathway_to_frames = classifier_directory + '/frames'\n",
    "pathway_to_skeletons = classifier_directory + '/skeletons'\n",
    "\n",
    "parent_directory = classifier_directory[:-11]\n",
    "webapp_directory = parent_directory + '/web_app'\n",
    "\n",
    "\n",
    "train_data = classifier_directory + '/train'\n",
    "test_data = classifier_directory + '/test'\n",
    "\n",
    "def listdir_nohidden(directory):\n",
    "    filelist = os.listdir(directory)\n",
    "    return [x for x in filelist\n",
    "            if not (x.startswith('.'))]\n",
    "\n",
    "def move_label(img): \n",
    "    label = img.split('.')[0]\n",
    "    if label == 'turn':\n",
    "        ohl = np.array([1,0,0])\n",
    "    elif label == 'cuddle':\n",
    "        ohl = np.array([0,1,0])\n",
    "    elif label == 'shadow':\n",
    "        ohl = np.array([0,0,1])\n",
    "    return ohl\n",
    "\n",
    "def train_data_with_label():\n",
    "    train_images = []\n",
    "    for ii in tqdm(listdir_nohidden(train_data)):\n",
    "        path = os.path.join(train_data, ii)\n",
    "        img = 1-np.absolute(np.genfromtxt(path, delimiter=',')) #cv2.imread(path)\n",
    "        train_images.append([np.array(img), move_label(ii)])\n",
    "    shuffle(train_images)\n",
    "    return train_images\n",
    "\n",
    "def test_data_with_label():\n",
    "    test_images = []\n",
    "    for ii in tqdm(listdir_nohidden(test_data)):\n",
    "        path = os.path.join(test_data, ii)\n",
    "        img = 1-np.absolute(np.genfromtxt(path, delimiter=',')) \n",
    "        test_images.append([np.array(img), move_label(ii)])\n",
    "    shuffle(test_images)\n",
    "    return test_images\n",
    "                         \n",
    "                         \n",
    "                         \n",
    "training_images = train_data_with_label()\n",
    "testing_images = test_data_with_label()\n",
    "\n",
    "\n",
    "tr_img_data = np.array([ii[0] for ii in training_images]).reshape(-1,36,60,1)\n",
    "tr_lbl_data = np.array([ii[1] for ii in training_images])\n",
    "\n",
    "tst_img_data = np.array([ii[0] for ii in testing_images]).reshape(-1,36,60,1)\n",
    "tst_lbl_data = np.array([ii[1] for ii in testing_images])\n",
    "                         \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "232/232 [==============================] - 0s 2ms/step - loss: 7.2368 - acc: 0.3621\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.7434 - acc: 0.3966\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 0s 184us/step - loss: 4.7470 - acc: 0.4052\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 0s 172us/step - loss: 4.7487 - acc: 0.3405\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 0s 184us/step - loss: 4.7481 - acc: 0.3405\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 0s 279us/step - loss: 4.7473 - acc: 0.3405\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 0s 191us/step - loss: 4.7462 - acc: 0.3491\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 0s 184us/step - loss: 4.7449 - acc: 0.5216\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 0s 206us/step - loss: 4.7433 - acc: 0.4526\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 0s 187us/step - loss: 4.7424 - acc: 0.3966\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 0s 180us/step - loss: 4.7414 - acc: 0.3966\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.7406 - acc: 0.3966\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 0s 185us/step - loss: 4.7399 - acc: 0.3966\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.7393 - acc: 0.3966\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 0s 195us/step - loss: 4.7384 - acc: 0.3966\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 0s 180us/step - loss: 4.7377 - acc: 0.3966\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 0s 191us/step - loss: 4.7365 - acc: 0.3966\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 0s 187us/step - loss: 4.7359 - acc: 0.3966\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 0s 174us/step - loss: 4.7342 - acc: 0.3966\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 0s 191us/step - loss: 4.7323 - acc: 0.3966\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 0s 183us/step - loss: 4.7300 - acc: 0.4095\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 0s 183us/step - loss: 4.7270 - acc: 0.4181\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 0s 188us/step - loss: 4.7233 - acc: 0.4353\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 0s 184us/step - loss: 4.7173 - acc: 0.4914\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 0s 193us/step - loss: 4.7120 - acc: 0.5647\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 0s 187us/step - loss: 4.7009 - acc: 0.5345\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.6835 - acc: 0.4871\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 0s 233us/step - loss: 4.6510 - acc: 0.5086\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 0s 187us/step - loss: 4.5857 - acc: 0.5647\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 0s 202us/step - loss: 4.7533 - acc: 0.6121\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 0s 210us/step - loss: 4.9123 - acc: 0.6336\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 0s 212us/step - loss: 4.6552 - acc: 0.6250\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 0s 201us/step - loss: 4.5461 - acc: 0.6164\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 0s 209us/step - loss: 4.6309 - acc: 0.6595\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 0s 223us/step - loss: 4.6194 - acc: 0.6681\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 0s 206us/step - loss: 4.6180 - acc: 0.6509\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 0s 240us/step - loss: 4.5843 - acc: 0.6810\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.4566 - acc: 0.6897\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 0s 185us/step - loss: 4.4873 - acc: 0.6552\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 0s 172us/step - loss: 4.4644 - acc: 0.6810\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 0s 186us/step - loss: 4.4387 - acc: 0.6940\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 0s 180us/step - loss: 4.4890 - acc: 0.6897\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 0s 192us/step - loss: 4.3983 - acc: 0.6983\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 0s 181us/step - loss: 4.3975 - acc: 0.7026\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 0s 181us/step - loss: 4.3764 - acc: 0.7112\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 0s 177us/step - loss: 4.4229 - acc: 0.7112\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 0s 175us/step - loss: 4.4127 - acc: 0.7198\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 0s 187us/step - loss: 4.3442 - acc: 0.7198\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 0s 185us/step - loss: 4.3412 - acc: 0.7241\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 0s 225us/step - loss: 4.3406 - acc: 0.7241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146eec5d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape = [36,60,1]))\n",
    "\n",
    "model.add(Conv2D(filters=60, kernel_size=[36,4],strides=[36,2],padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=4, padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters=60, kernel_size=[18,4],strides=[18,2],padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=4, padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters=60, kernel_size=[9,4],strides=[9,2],padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=4, padding='same'))\n",
    "\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(3,activation='relu'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=tr_img_data,y=tr_lbl_data,epochs=50,batch_size=100)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 68.33%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(tst_img_data, tst_lbl_data, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(webapp_directory + '/model_.h5')\n",
    "model.save(classifier_directory + '/model_.h5')\n",
    "\n",
    "# Save the weights\n",
    "\n",
    "# model.save_weights(webapp_directory + '/model_weights.h5') #THIS ONE\n",
    "model.save_weights(classifier_directory + '/model_weights.h5') #THIS ONE\n",
    "\n",
    "# # Save the model architecture\n",
    "# with open(webapp_directory + 'model_architecture.json', 'w') as f:\n",
    "#     f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
